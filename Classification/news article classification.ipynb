{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"../data/\"\n",
    "labels = ['politics','sport','health','money','local']\n",
    "\n",
    "if os.path.exists(\"../data/data_df.csv\"):\n",
    "    data_df = pd.DataFrame.from_csv(\"../data/data_df.csv\")\n",
    "else:\n",
    "    data = []\n",
    "    for l in labels:\n",
    "        for name in os.listdir(data_dir + l):\n",
    "            article = json.load(open(data_dir + l + \"/\" + name))\n",
    "            text = article['text']\n",
    "            if text.endswith(\"Read More\"):\n",
    "                text = text[:-len(\"Read More\")]\n",
    "            art_list = [article['title'],text,l]\n",
    "            data.append(art_list)\n",
    "    data = np.array(data)\n",
    "    data_df = pd.DataFrame(data,columns=['title','text','label'])\n",
    "    data_df.to_csv(\"../data/data_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data\n",
    "1.  categories into discrete numerical values;\n",
    "2.  Transform all words to lowercase;\n",
    "3.  Remove all punctuations and stopwords.\n",
    "4.  Tokenization and stemming lemmatization the tokens.\n",
    "5.  Replaced numerical values with '#num#' to reduce vocabulary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.stem.porter import *\n",
    "import nltk \n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "if (os.path.exists(\"../data/data_df_processed.csv\") is not True):\n",
    "    data_df_processed = data_df.copy()\n",
    "    data_df_processed['label'] = data_df.label.map({ 'local':0, 'politics': 1, 'sport': 2, 'health': 3, 'money': 4})\n",
    "    data_df_processed['title'] = data_df.title.map(\n",
    "        lambda x: x.lower().translate(str.maketrans('','', string.punctuation))\n",
    "    )\n",
    "    data_df_processed['text'] = data_df.text.map(\n",
    "        lambda x: x.lower().translate(str.maketrans('','', string.punctuation))\n",
    "    )\n",
    "\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    data_df_processed['title_stem'] = data_df_processed.title.map(\n",
    "        lambda x: ' '.join([stemmer.stem(w) for w in nltk.word_tokenize(x) if w not in stopwords.words('english')]))\n",
    "\n",
    "    data_df_processed['text_stem'] = data_df_processed.text.map(\n",
    "        lambda x: ' '.join([stemmer.stem(w) for w in nltk.word_tokenize(x) if w not in stopwords.words('english')]))\n",
    "\n",
    "    regex = re.compile(r\"\\d+\", re.IGNORECASE)\n",
    "\n",
    "    data_df_processed['title_stem'] = data_df_processed.title_stem.map(\n",
    "        lambda x: regex.sub(\"spnumsp\", x))\n",
    "\n",
    "    data_df_processed['text_stem'] = data_df_processed.text_stem.map(\n",
    "        lambda x: regex.sub(\"spnumsp\", x))\n",
    "    \n",
    "    data_df_processed['title+text_stem'] = data_df_processed['text_stem'].values + data_df_processed['title_stem'].values\n",
    "    \n",
    "    data_df_processed['title+text'] = data_df_processed['text'].values + data_df_processed['title'].values\n",
    "    \n",
    "    data_df_processed['title_nonum'] = data_df_processed.title.map(\n",
    "        lambda x: regex.sub(\"spnumsp\", x))\n",
    "\n",
    "    data_df_processed['text_nonum'] = data_df_processed.text.map(\n",
    "        lambda x: regex.sub(\"spnumsp\", x))\n",
    "    \n",
    "    lemmer = WordNetLemmatizer()\n",
    "    data_df_processed['title_lem'] = data_df_processed.title.map(\n",
    "        lambda x: ' '.join([lemmer.lemmatize(w) for w in nltk.word_tokenize(x) if w not in stopwords.words('english')]))\n",
    "\n",
    "\n",
    "    data_df_processed['text_lem'] = data_df_processed.text.map(\n",
    "        lambda x: ' '.join([lemmer.lemmatize(w) for w in nltk.word_tokenize(x) if w not in stopwords.words('english')]))\n",
    "\n",
    "    data_df_processed['title+text_lem'] = data_df_processed['text_lem'].values + data_df_processed['title_lem'].values\n",
    "    data_df_processed.to_csv(\"../data/data_df_processed.csv\")\n",
    "else:\n",
    "    data_df_processed = pd.DataFrame.from_csv(\"../data/data_df_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_processed.to_csv(\"../data/data_df_processed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset:  (7608,)\n",
      "Test dataset:  (2537,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#     data_df_processed['text_nonum'].values + data_df_processed['title_nonum'].values , \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_df_processed['text'].values,\n",
    "    data_df_processed['label'].values, \n",
    "    random_state = 1\n",
    ")\n",
    "\n",
    "print(\"Training dataset: \", X_train.shape)\n",
    "print(\"Test dataset: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features\n",
    "Apply bag of words processing to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vector = CountVectorizer(stop_words = 'english', ngram_range=(1, 4),  max_features=None, min_df=2)\n",
    "# count_vector = CountVectorizer(stop_words = 'english')\n",
    "training_data = count_vector.fit_transform(X_train)\n",
    "testing_data = count_vector.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Multinomial Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(training_data, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.89948758376\n",
      "Recall score:  0.89948758376\n",
      "Precision score:  0.899908688368\n",
      "F1 score:  0.8995475469\n"
     ]
    }
   ],
   "source": [
    "predictions = naive_bayes.predict(testing_data)\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, predictions))\n",
    "print(\"Recall score: \", recall_score(y_test, predictions, average = 'weighted'))\n",
    "print(\"Precision score: \", precision_score(y_test, predictions, average = 'weighted'))\n",
    "print(\"F1 score: \", f1_score(y_test, predictions, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# no stem, text+title, 0.880961765865\n",
    "# no stem no number , text+title, 0.881355932203\n",
    "# stem, text+title, 0.871501773749\n",
    "# title_lem, ngram_range=(1, 4),  max_features=None, min_df = 2, 0.759952700039\n",
    "# title, ngram_range=(1, 4),  max_features=None, min_df = 2, 0.745368545526\n",
    "\n",
    "# text+title, ngram_range=(1, 2),  max_features=None, min_df = 5, 0.885691761924\n",
    "# text+title, ngram_range=(1, 2),  max_features=None, min_df = 5, 0.889239258967\n",
    "# text+title, ngram_range=(1, 2),  max_features=None, min_df = 10, 0.878990934174\n",
    "# text+title, ngram_range=(1, 2),  max_features=None, min_df = 8, 0.884509262909\n",
    "# text+title, ngram_range=(1, 2),  max_features=None, min_df = 3, 0.896728419393\n",
    "# text+title, ngram_range=(1, 2),  max_features=None, min_df = 2, 0.899881750099\n",
    "# text+title, ngram_range=(1, 2),  max_features=None, min_df = 1, 0.882538431218\n",
    "# text+title, ngram_range=(1, 2),  max_features=None, min_df = 4, 0.891604256996\n",
    "# text+title, ngram_range=(1, 3),  max_features=None, min_df = 2, 0.900670082775\n",
    "# text+title, ngram_range=(1, 4),  max_features=None, min_df = 2, 0.90185258179\n",
    "# text+title_lem, ngram_range=(1, 4),  max_features=None, min_df = 2, 0.901064249113\n",
    "# text_lem, ngram_range=(1, 4),  max_features=None, min_df = 2, 0.898305084746\n",
    "# text, ngram_range=(1, 4),  max_features=None, min_df = 2, 0.89948758376\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>title_stem</th>\n",
       "      <th>text_stem</th>\n",
       "      <th>title+text_stem</th>\n",
       "      <th>title+text</th>\n",
       "      <th>title_lem</th>\n",
       "      <th>text_lem</th>\n",
       "      <th>title+text_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a wild weekend of trump tweets</td>\n",
       "      <td>washington cnn even by his standards president...</td>\n",
       "      <td>1</td>\n",
       "      <td>wild weekend trump tweet</td>\n",
       "      <td>washington cnn even standard presid donald tru...</td>\n",
       "      <td>washington cnn even standard presid donald tru...</td>\n",
       "      <td>washington cnn even by his standards president...</td>\n",
       "      <td>wild weekend trump tweet</td>\n",
       "      <td>washington cnn even standard president donald ...</td>\n",
       "      <td>washington cnn even standard president donald ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scaramucci suggests trump may veto bipartisan ...</td>\n",
       "      <td>story highlights gop leaders havent commented ...</td>\n",
       "      <td>1</td>\n",
       "      <td>scaramucci suggest trump may veto bipartisan r...</td>\n",
       "      <td>stori highlight gop leader havent comment pote...</td>\n",
       "      <td>stori highlight gop leader havent comment pote...</td>\n",
       "      <td>story highlights gop leaders havent commented ...</td>\n",
       "      <td>scaramucci suggests trump may veto bipartisan ...</td>\n",
       "      <td>story highlight gop leader havent commented po...</td>\n",
       "      <td>story highlight gop leader havent commented po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>top state department official out after 3 months</td>\n",
       "      <td>story highlights maliz beams had been appointe...</td>\n",
       "      <td>1</td>\n",
       "      <td>top state depart offici spnumsp month</td>\n",
       "      <td>stori highlight maliz beam appoint counselor s...</td>\n",
       "      <td>stori highlight maliz beam appoint counselor s...</td>\n",
       "      <td>story highlights maliz beams had been appointe...</td>\n",
       "      <td>top state department official 3 month</td>\n",
       "      <td>story highlight maliz beam appointed counselor...</td>\n",
       "      <td>story highlight maliz beam appointed counselor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>athletes call out trump after national anthem ...</td>\n",
       "      <td>new york cnn president donald trump drew the i...</td>\n",
       "      <td>1</td>\n",
       "      <td>athlet call trump nation anthem curri remark</td>\n",
       "      <td>new york cnn presid donald trump drew ire prof...</td>\n",
       "      <td>new york cnn presid donald trump drew ire prof...</td>\n",
       "      <td>new york cnn president donald trump drew the i...</td>\n",
       "      <td>athlete call trump national anthem curry remark</td>\n",
       "      <td>new york cnn president donald trump drew ire p...</td>\n",
       "      <td>new york cnn president donald trump drew ire p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chief of staff to congresswoman placed on leav...</td>\n",
       "      <td>story highlights rep brenda lawrence wrote pro...</td>\n",
       "      <td>1</td>\n",
       "      <td>chief staff congresswoman place leav follow se...</td>\n",
       "      <td>stori highlight rep brenda lawrenc wrote propo...</td>\n",
       "      <td>stori highlight rep brenda lawrenc wrote propo...</td>\n",
       "      <td>story highlights rep brenda lawrence wrote pro...</td>\n",
       "      <td>chief staff congresswoman placed leave followi...</td>\n",
       "      <td>story highlight rep brenda lawrence wrote prop...</td>\n",
       "      <td>story highlight rep brenda lawrence wrote prop...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                     a wild weekend of trump tweets   \n",
       "1  scaramucci suggests trump may veto bipartisan ...   \n",
       "2   top state department official out after 3 months   \n",
       "3  athletes call out trump after national anthem ...   \n",
       "4  chief of staff to congresswoman placed on leav...   \n",
       "\n",
       "                                                text  label  \\\n",
       "0  washington cnn even by his standards president...      1   \n",
       "1  story highlights gop leaders havent commented ...      1   \n",
       "2  story highlights maliz beams had been appointe...      1   \n",
       "3  new york cnn president donald trump drew the i...      1   \n",
       "4  story highlights rep brenda lawrence wrote pro...      1   \n",
       "\n",
       "                                          title_stem  \\\n",
       "0                           wild weekend trump tweet   \n",
       "1  scaramucci suggest trump may veto bipartisan r...   \n",
       "2              top state depart offici spnumsp month   \n",
       "3       athlet call trump nation anthem curri remark   \n",
       "4  chief staff congresswoman place leav follow se...   \n",
       "\n",
       "                                           text_stem  \\\n",
       "0  washington cnn even standard presid donald tru...   \n",
       "1  stori highlight gop leader havent comment pote...   \n",
       "2  stori highlight maliz beam appoint counselor s...   \n",
       "3  new york cnn presid donald trump drew ire prof...   \n",
       "4  stori highlight rep brenda lawrenc wrote propo...   \n",
       "\n",
       "                                     title+text_stem  \\\n",
       "0  washington cnn even standard presid donald tru...   \n",
       "1  stori highlight gop leader havent comment pote...   \n",
       "2  stori highlight maliz beam appoint counselor s...   \n",
       "3  new york cnn presid donald trump drew ire prof...   \n",
       "4  stori highlight rep brenda lawrenc wrote propo...   \n",
       "\n",
       "                                          title+text  \\\n",
       "0  washington cnn even by his standards president...   \n",
       "1  story highlights gop leaders havent commented ...   \n",
       "2  story highlights maliz beams had been appointe...   \n",
       "3  new york cnn president donald trump drew the i...   \n",
       "4  story highlights rep brenda lawrence wrote pro...   \n",
       "\n",
       "                                           title_lem  \\\n",
       "0                           wild weekend trump tweet   \n",
       "1  scaramucci suggests trump may veto bipartisan ...   \n",
       "2              top state department official 3 month   \n",
       "3    athlete call trump national anthem curry remark   \n",
       "4  chief staff congresswoman placed leave followi...   \n",
       "\n",
       "                                            text_lem  \\\n",
       "0  washington cnn even standard president donald ...   \n",
       "1  story highlight gop leader havent commented po...   \n",
       "2  story highlight maliz beam appointed counselor...   \n",
       "3  new york cnn president donald trump drew ire p...   \n",
       "4  story highlight rep brenda lawrence wrote prop...   \n",
       "\n",
       "                                      title+text_lem  \n",
       "0  washington cnn even standard president donald ...  \n",
       "1  story highlight gop leader havent commented po...  \n",
       "2  story highlight maliz beam appointed counselor...  \n",
       "3  new york cnn president donald trump drew ire p...  \n",
       "4  story highlight rep brenda lawrence wrote prop...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
